{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a25693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import *\n",
    "import glob\n",
    "import shutil\n",
    "import IPython.display as ipd\n",
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bce22657",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/net/store/cv/users/ybrima/scratch/data')\n",
    "ZIP_PATH =  Path( DATA_PATH, os.listdir(DATA_PATH)[-1])\n",
    "INPUT_PATH = Path('/net/store/cv/users/ybrima/scratch/data/archive/16000_pcm_speeches/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dab874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = os.listdir(INPUT_PATH)\n",
    "FRAME_LENGHT =  1024\n",
    "SAMPLE_RATE =  16000\n",
    "HOP_LENGTH =  512\n",
    "n_fft=2048\n",
    "num_mfcc=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,output_shape):\n",
    "    \"\"\" This function builds a functional model\"\"\"\n",
    "    \n",
    "\n",
    "    inputs =  keras.Input(shape=input_shape,name=\"input_layer\")\n",
    "    x =  keras.layers.Flatten()(inputs)\n",
    "    \n",
    "    x =  keras.layers.Dense(32,activation=\"relu\")(x)\n",
    "    x =  keras.layers.BatchNormalization()(x)\n",
    "    x =  keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x =  keras.layers.Dense(64,activation=\"relu\")(x)\n",
    "    x =  keras.layers.BatchNormalization()(x)\n",
    "    x =  keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x =  keras.layers.Dense(128,activation=\"relu\")(x)\n",
    "    x =  keras.layers.BatchNormalization()(x)\n",
    "    x =  keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x =  keras.layers.Dense(64,activation=\"relu\")(x)\n",
    "    x =  keras.layers.BatchNormalization()(x)\n",
    "    x =  keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x =  keras.layers.Dense(32,activation=\"relu\")(x)\n",
    "    x =  keras.layers.BatchNormalization()(x)\n",
    "    x =  keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs =  keras.layers.Dense(output_shape,activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "    model =  keras.Model(inputs=inputs,outputs=outputs,name=\"speaker_model\")\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.RMSprop(),metrics=[\"accuracy\"],)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b217ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(INPUT_PATH):\n",
    "    ds =  {'file': [], 'class': []}\n",
    "    for d in os.listdir(INPUT_PATH):\n",
    "        temp =  Path(INPUT_PATH, d)\n",
    "        if(os.path.isdir(temp)):\n",
    "            for file in temp.glob(\"**/*.wav\"):\n",
    "                filename =  Path(temp,file)\n",
    "                ds['file'].append(filename)\n",
    "                ds['class'].append(CLASSES.index(d))\n",
    "    data = pd.DataFrame(ds)\n",
    "    return data,CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a5505a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, CLASSES = get_files(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c700581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array(df,file_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    X  = []\n",
    "    Q = []\n",
    "    y =  []\n",
    "    for k in range(df.shape[0]):\n",
    "        r =  df.iloc[k]\n",
    "        #   Loading the audio file \n",
    "        signal,sample_rate = librosa.load(r['file'], sr=SAMPLE_RATE)\n",
    "        \n",
    "        X.append(signal)\n",
    "        y.append(y)\n",
    "        \n",
    "        # extract mfcc\n",
    "        mfcc = librosa.feature.mfcc(signal, SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "        Q.append(mfcc)\n",
    "    \n",
    "    X =  np.array(X)\n",
    "    Q =  np.array(Q)\n",
    "    y =  np.array(y)\n",
    "    np.savez(file_path,x=X,q=Q,y=y)\n",
    "    print(f\"Data written to storage successfully, path = {file_path}/speakers.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccce5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(ds,INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec900c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (30,13)\n",
    "output_shape =  len(CLASSES)\n",
    "model = build_model(input_shape,output_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
