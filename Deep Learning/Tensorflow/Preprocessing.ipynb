{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "26db1ec4-b266-403e-a32f-5fb87f09e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f54b8010-ac61-424f-9b49-153737b85993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    # pp = \"/net/projects/scratch/winter/valid_until_31_July_2022/krumnack/animal-communication-data/Chimp_IvoryCoast/manually_verified_2s/chimp_only_23112020_with_ids\"\n",
    "    files = [os.path.join(path,f) for f in os.listdir(path) if os.path.isfile(os.path.join(path,f)) and f.endswith('.wav')]\n",
    "    return files\n",
    "\n",
    "\n",
    "def sanitize(files):\n",
    "    ds =  {'file':[], \"class\":[]}\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        ds['file'].append(f)\n",
    "        ds['class'].append(f[f.rfind(\"/\")+12:][:f[f.rfind(\"/\")+12:].index('_')])\n",
    "        \n",
    "    #next we want to select files that belong to class >=  100 samples\n",
    "    \n",
    "    # pd.Series(data['class'].unique()).sort_values()\n",
    "    l = ['kub','woo','rom','jac','sum','kub-phsm','kub-phtbsm','uta','ish-phsm','jul','rom-phsm','kub-phtb','woo-phsm']\n",
    "    \n",
    "    data = pd.DataFrame(ds)\n",
    "    \n",
    "    #next we concatinate the selected samples per class into a single data frame\n",
    "    \n",
    "    ddf = data.loc[data['class'] == l[0]].copy()\n",
    "    for i in range(1,len(l)):\n",
    "        ddf = pd.concat([ddf, data.loc[data['class'] == l[i]]], axis = 0)\n",
    "    return ddf\n",
    "\n",
    "\n",
    "def save_mfcc(df, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": [],\n",
    "        'melspec': []\n",
    "    }\n",
    "\n",
    "    for k in range(df.shape[0]):\n",
    "        r =  df.iloc[k]\n",
    "        \n",
    "        #   Loading the audio file \n",
    "        signal, sample_rate = librosa.load(r['file'], sr=SAMPLE_RATE)\n",
    "        \n",
    "        # extract mfcc\n",
    "        mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        \n",
    "        mel_spectrogram = librosa.feature.melspectrogram(signal,sr=sample_rate,n_fft=n_fft,hop_length=hop_length,n_mels=num_mfcc)\n",
    "        log_mel_spectrogram =  librosa.power_to_db(mel_spectrogram,ref=np.max)\n",
    "        mfcc = mfcc.T\n",
    "        spec = log_mel_spectrogram.T\n",
    "        w,h = 87, 13\n",
    "        if(mfcc.shape[0] == w and mfcc.shape[1] == h):\n",
    "            data[\"mapping\"].append(r['class'])\n",
    "            data['labels'].append(l.index(r['class']))\n",
    "            data[\"mfcc\"].append(mfcc.tolist())\n",
    "            data[\"melspec\"].append(spec.tolist())\n",
    "        \n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44f961a-4132-4711-8432-06e001c92f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = \"/net/projects/scratch/winter/valid_until_31_July_2022/krumnack/animal-communication-data/Chimp_IvoryCoast/manually_verified_2s/chimp_only_23112020_with_ids\"\n",
    "files =  get_files(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a3ce8ea5-6b0f-4fb4-9cc2-90455790a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sanitize(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3e8f6863-7667-4628-89d3-dabcbb3faf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = \"data_10.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 30 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b9b4b9cf-dbdd-4a0a-b41f-caf920037702",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mfcc(ddf, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2d06e21e-3d91-4728-903f-318f6500175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sanitized_vocalization', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adc118-c84b-4f62-8906-e2b53619ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
