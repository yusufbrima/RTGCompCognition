{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d40ba8-4f0e-4b27-9460-ea7116211ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from celluloid import Camera # getting the camera\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import librosa\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import img_to_array \n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions \n",
    "from tensorflow.keras.applications import VGG16, ResNet50, VGG19, DenseNet121, InceptionV3, Xception\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_preprocessing.image.dataframe_iterator import DataFrameIterator\n",
    "from matplotlib.offsetbox import ( OffsetImage,\n",
    "                                  AnnotationBbox)\n",
    "from IPython.display import HTML # to show the animation in Jupyter\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974ed7a1-c2b3-4d2d-9b63-244b4add7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"Loads training dataset from json file.\n",
    "        :param data_path (str): Path to json file containing data\n",
    "        :return X (ndarray): Inputs\n",
    "        :return y (ndarray): Targets\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    X = np.array(data[\"mfcc\"],dtype=np.float64)\n",
    "    Z = np.array(data[\"melspec\"],dtype=np.float64)\n",
    "    Q = np.array(data[\"spect\"],dtype=np.float64)\n",
    "    y = np.array(data[\"labels\"])\n",
    "    mp = data['mapping']\n",
    "    print(\"Data succesfully loaded!\")\n",
    "\n",
    "    return  X, y,Z,Q,mp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Plots accuracy/loss for training/validation set as a function of the epochs\n",
    "        :param history: Training history of model\n",
    "        :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b379555e-9aed-493c-abd7-1e34022e506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to json file that stores MFCCs and genre labels for each processed segment\n",
    "paths = \"/net/projects/scratch/winter/valid_until_31_July_2022/ybrima/data\"\n",
    "\n",
    "JSON_PATH = f\"{paths}/data_13.json\"\n",
    "\n",
    "# Audio hyperparamters\n",
    "sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42f4e81-65ec-4acb-8fa7-8348656088fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x,sr):\n",
    "    \n",
    "    if(x.shape[0] > x.shape[1]):\n",
    "        x =  x.T\n",
    "    librosa.display.specshow(x.T, sr=sr, x_axis='time',y_axis=\"log\",hop_length=HOP_LENGTH)\n",
    "    plt.colorbar(format='%+2.f')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab04c97-00fb-4e07-806b-275cbdddbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9032eaeb-b1eb-453e-8a29-f4626c5b23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test): \n",
    "    mu, sigma = train.mean(),train.std()\n",
    "    train = (train - mu) / sigma \n",
    "    mu, sigma = test.mean(),test.std()\n",
    "    test = (test - mu) / sigma \n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd4cb4a-70ea-45ba-8b74-099050587f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, validation_size):\n",
    "    \"\"\"Loads data and splits it into train, validation and test sets.\n",
    "    :param test_size (float): Value in [0, 1] indicating percentage of data set to allocate to test split\n",
    "    :param validation_size (float): Value in [0, 1] indicating percentage of train set to allocate to validation split\n",
    "    :return X_train (ndarray): Input training set\n",
    "    :return X_validation (ndarray): Input validation set\n",
    "    :return X_test (ndarray): Input test set\n",
    "    :return y_train (ndarray): Target training set\n",
    "    :return y_validation (ndarray): Target validation set\n",
    "    :return y_test (ndarray): Target test set\n",
    "    \"\"\"\n",
    "\n",
    "    # load data\n",
    "    X, y,Z,Q,mp = load_data(JSON_PATH)\n",
    "\n",
    "    # create train, validation and test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Z, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # add an axis to input sets\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee804f1-f0b5-4c13-9f1e-642a4106fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \"\"\"Generates CNN model\n",
    "    :param input_shape (tuple): Shape of input set\n",
    "    :return model: CNN model\n",
    "    \"\"\"\n",
    "\n",
    "    # build network topology\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(13, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98da61e-6fe3-481b-83d0-77f36273d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    \"\"\"Predict a single sample using the trained model\n",
    "    :param model: Trained classifier\n",
    "    :param X: Input data\n",
    "    :param y (int): Target\n",
    "    \"\"\"\n",
    "\n",
    "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
    "    X = X[np.newaxis, ...] # array shape (1, 130, 13, 1)\n",
    "\n",
    "    # perform prediction\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # get index with max value\n",
    "    predicted_index = np.argmax(prediction, axis=1)\n",
    "\n",
    "    print(\"Target: {}, Predicted label: {}\".format(y, predicted_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce828d-e24b-46b9-bdec-13e38d7feb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train, validation, test splits\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b061d-2545-4797-aed5-1592816b408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "used = set()\n",
    "label = [x for x in mp if x not in used and (used.add(x) or True)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae936a-6063-4097-af16-3c04a8c49036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# compile model\n",
    "\n",
    "optim_params = dict(\n",
    "    learning_rate = 0.0001,\n",
    "    momentum = 0.9394867962846013,\n",
    "    decay = 0.0001\n",
    ")\n",
    "\n",
    "optimiser = keras.optimizers.SGD(**optim_params)\n",
    "model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1177af-c7b1-4b29-ac74-a624594a750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "\n",
    "check_point= ModelCheckpoint(\n",
    "    # 'model_v2.best.h5', \n",
    "    'weighted_model_v2.best.h5', \n",
    "    monitor='val_loss', verbose=1, \n",
    "    save_best_only=True, save_weights_only=False, save_freq=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=0.00001\n",
    ")\n",
    "\n",
    "early_stop= EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0.001, patience=11, verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e8228-b96a-4a6a-b570-5412ce9fe0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30,callbacks=[check_point, early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fee14-987c-44fe-bab8-1d1f009b0535",
   "metadata": {},
   "source": [
    "# Working with standard CNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b58797-0388-4307-98bb-1590744e70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy/error for training and validation\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887c4d3e-d8b6-4a45-afc1-daa8af4daf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "NUM_CLASSES = 13\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "# CLASS_MODE = 'binary'\n",
    "COLOR_MODE = 'grayscale'\n",
    "TARGET_SIZE = (87, 87)\n",
    "EPOCHS = 50\n",
    "SEED = 214\n",
    "input_shape = (87, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa48d63-e3b5-44dc-a4ec-074317ecfc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: input_1, trainable: False\n",
      "layer 1: block1_conv1, trainable: False\n",
      "layer 2: block1_conv2, trainable: False\n",
      "layer 3: block1_pool, trainable: False\n",
      "layer 4: block2_conv1, trainable: False\n",
      "layer 5: block2_conv2, trainable: False\n",
      "layer 6: block2_pool, trainable: False\n",
      "layer 7: block3_conv1, trainable: False\n",
      "layer 8: block3_conv2, trainable: False\n",
      "layer 9: block3_conv3, trainable: False\n",
      "layer 10: block3_conv4, trainable: True\n",
      "layer 11: block3_pool, trainable: True\n",
      "layer 12: block4_conv1, trainable: True\n",
      "layer 13: block4_conv2, trainable: True\n",
      "layer 14: block4_conv3, trainable: True\n",
      "layer 15: block4_conv4, trainable: True\n",
      "layer 16: block4_pool, trainable: True\n",
      "layer 17: block5_conv1, trainable: True\n",
      "layer 18: block5_conv2, trainable: True\n",
      "layer 19: block5_conv3, trainable: True\n",
      "layer 20: block5_conv4, trainable: True\n",
      "layer 21: block5_pool, trainable: True\n",
      "layer 22: flatten, trainable: True\n",
      "layer 23: dense, trainable: True\n"
     ]
    }
   ],
   "source": [
    "def print_layers(model):\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        print(\"layer {}: {}, trainable: {}\".format(idx, layer.name, layer.trainable))\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=TARGET_SIZE+(3,) )\n",
    "# base_model = VGG16(weights='weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=TARGET_SIZE+(3,))\n",
    "\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=TARGET_SIZE+(3,))\n",
    "\n",
    "base_model = VGG19(weights=None, include_top=False, input_shape=input_shape)\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=TARGET_SIZE+(3,))\n",
    "# base_model = DenseNet121( weights='weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=TARGET_SIZE+(3,))\n",
    "# base_model = InceptionV3(weights='weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=TARGET_SIZE+(3,))\n",
    "# can also try other architectures\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "for layer in model.layers[0:-14]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8585451e-8a5b-4e75-8b3a-ae5b051fac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 87, 256, 1)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 87, 256, 64)       640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 87, 256, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 43, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 43, 128, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 43, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 21, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 21, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 10, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 16, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                106509    \n",
      "=================================================================\n",
      "Total params: 20,129,741\n",
      "Trainable params: 18,395,405\n",
      "Non-trainable params: 1,734,336\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a343c6-fef1-4cba-a75b-6d1386916a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 87, 256, 1)]      0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 87, 256, 64)       640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 87, 256, 64)       36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 43, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 43, 128, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 43, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 21, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 21, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 21, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 10, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 10, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 10, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 5, 16, 512)        0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 5, 16, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 13)                106509    \n",
      "=================================================================\n",
      "Total params: 20,129,741\n",
      "Trainable params: 18,395,405\n",
      "Non-trainable params: 1,734,336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "optim_params = dict(\n",
    "    learning_rate = 0.0001,\n",
    "    momentum = 0.9394867962846013,\n",
    "    decay = 0.0001\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=SGD(**optim_params),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a30b6-6e52-4866-aa4a-9de8d1259fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
